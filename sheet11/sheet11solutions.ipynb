{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Osnabr√ºck University - Machine Learning (Summer Term 2016) - Prof. Dr.-Ing. G. Heidemann, Ulf Krumnack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise Sheet 11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This week's sheet is intended to revise the topics from the lecture. It does not need to be solved in order to qualify for the final exam but it is highly recommended for preparation. If you would like to discuss your solutions with your tutor please upload your sheet to your group's Stud.IP folder before the end of **Sunday, July 3, 2016**. Also if you hit any question that should be discussed in more detail, feel free to contact your groups' designated tutor or whomever of us you run into first before that date."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 1: Concept Learning [2 Points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Concept Learning\n",
    "\n",
    "What is Concept Learning? Is it supervised? Is it local?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concept learning aims at acquiring knowledge that allows to distinguish exemplars from non exemplars of a given category (concept). It can be formalized as learning a unary predicate $p_c$ on the domain $X$ or equivalently an indicator function $c:X\\to\\{0,1\\}$.\n",
    "\n",
    "Concept learning is usually supervised: the teacher tells the learner if an example falls under the concept or not.\n",
    "\n",
    "As soon as there are is some metric given on the data, there may be local and global concept learners. One may for example use a nearest neighbor learner (local) or a multilayer-perceptron (global) to learn concepts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Find-S\n",
    "Describe the Find-S Algorithm in pseudo code. What is its inductive bias? What are its advantages and drawbacks?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    1. Initialize $h$ to the most specific hypothesis in H.\n",
    "    2. For each positive training instance x do\n",
    "           For each attribute constraint $a_i$ in h do\n",
    "               If ($a_$i is not satisfied by x) then\n",
    "                   Replace $a_i$ in h by the next more general constraint\n",
    "                     that is satisfied by x.\n",
    "               End if\n",
    "           End for\n",
    "       End for\n",
    "    3. Output h.\n",
    "\n",
    "Inductive Bias: The target concept can be described in its hypothesis space (in our case: it is a conjunction of features). All instances are negative instances unless demonstrated otherwise.\n",
    "\n",
    "Drawback: it does not take negative instances into account."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Hypotheses space\n",
    "\n",
    "What is the hypotheses space for Candidate-Elimination used in the lecture?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hypothesis space for Candidate-Elimination spreads between the most general and most specific hypotheses. The other hypotheses are made up by conjunction of features which biases the learner and makes it impossible to find a disjunctive solution.\n",
    "\n",
    "The version space on the other hand is a subset of the hypotheses space. It is the set of all hypotheses between and including the general and the specific boundary.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 2: Decision Trees [2 Points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Overfitting\n",
    "What is overfitting? How can it be avoided?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overfitting means an overly specific adaptation of the learner to the training data. Not only the general structure of the training data has been learned, but also its specific noise, i.e. artifacts, are learned and hence the learner looses the capability to generalize and work on other data.\n",
    "\n",
    "Overfitting can be detected by using a separate test data set. If the error on the test data increases during training, this indicates overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Pruning\n",
    "\n",
    "Name one method for pruning a decision tree and describe it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pruning can be applied to reduce overfitting of a decision tree. Two types of pruning have been introduced in the lecture:\n",
    "\n",
    "*Reduced error pruning:* removes nodes from the decision tree to achieve better generalization on the test set.\n",
    "\n",
    "*Rule based pruning:* translate the decision tree into a set of rules and then prune an individual rule by removing any preconditions that result in improving its accuracy on the\n",
    "validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Information gain\n",
    "What are entropy and information gain? Provide explanation and formulae. How are they used in ID3?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entropy measures the inhomogeneity of a data set (the minimal number of bits needed to encode elements from the set) \n",
    "$$E(S) = -p_{+}\\log_2 p_{+} - p_{-}\\log_2p_{-}$$\n",
    "where $p_{+}$ denotes the fraction of positive and $p_{-}$ that of negative examples in the data set. A set $S$ with only positive (or only negative) examples would have no entropy (i.e. $E(S)=0$), while a set with the same number of positive and negative examples has maximal entropy ($E(S)=1$).\n",
    "\n",
    "Information gain is the expected reduction in entropy due to splitting the data set $S$ based on one attribute $A$: denote for every value $v\\in\\operatorname{Values}(A)$ the subset of elements from $S$ where $A=v$ by $S_v$. Then the information gain is given by\n",
    "$$\\operatorname{Gain}(S,A) = E(S) - \\sum_{v\\in\\operatorname{Values}(A)}E(S_v)\\cdot\\frac{|S_v|}{|S|}$$\n",
    "that is, from the entropy of $S$ the entropy values for $S_v$ are subtracted and weighted by their respective sizes. If the subsets $S_v$ are all homogeneous ($E(S_v)=0$), then the information gain is maximal, namely $E(S)$, i.e. the data set can be fully explained by the single attribute $A$. On the other hand, if all $S_v$ have maximal entropy,  no information is gained by splitting based on $A$. In practice, something between these extremes will be the case.\n",
    "\n",
    "ID3 places the node with highest information gain at the root of the decision tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 3: Data Mining [2 Points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Missing values\n",
    "\n",
    "How can you deal with missing values? Name an important algorithm and explain how to use it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data records with missing values may be simply ignored, or one may try to \"fix\" the record by inserting artificial values into empty slots. The most simple way is to insert just zeros (or some other value) but this will lead to poor data quality. Better approaches try to use statistical properties of the data set to introduce \"natural\" fillers. One approach is to use the mean of the missing attribute, however this ignores possible dependencies between the different attributes. A more sophisticated approach is expectation maximization (EM) to estimate the joint probability distribution of all attributes in an iterative process. Once it is computed, one can use it to determine the most likely value for the missing datapoint."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Outliers\n",
    "\n",
    "What are outliers? Can we detect them? If so, how?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An outlier is a value that seemingly does not belong to the rest of the data. It is probably caused by some measurement error (but it may also reflect some real phenomenon).\n",
    "\n",
    "A simple method to detect outliers is to consider their distances from the mean (or median) of the full data set. If this is too large (e.g. greater than 3 standard deviations), the data point is considered to be an outlier (z-test). The Rosner test iteratively removes those outliers until the dataset does not contain anymore of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) \n",
    "What does the Q-function express in the EM algorithm?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The EM algorithm aims at finding model parameters $\\theta$ that best explain observed data $x$ (which may have missing values $h$). It does so by alternating steps of calculating the expected value of the (log) likelihood function $L(\\theta,x,h)$, using the current estimated parameters $\\theta_t$ (E step), and then finding parameter values $\\theta'$ that maximize this quantity (M step). The $Q$-function expresses the expected likelihood function:\n",
    "$$Q(\\theta\\mid\\theta_{t}) = E_{h\\mid x,\\theta_t}[\\log L(\\theta,x,h)] = \\int P(h\\mid x,\\theta_t)\\cdot \\log P(h\\mid x,\\theta)\\operatorname{d} h+\\log P(x\\mid\\theta)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 4: Clustering [2 Points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Clustering\n",
    "\n",
    "Explain the difference between single-linkage and complete-linkage clustering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Single-linkage clustering is based on the *minimum distance* that defines the distance between two clusters from the distance of their closest points. Single-linkage clustering tends to chaining.\n",
    "\n",
    "Complete-linkage clustering is based on the *maximum distance* that defines the distance of two clusters to be the maximal distance of two of their points. Complete linkage clustering prefers compact clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Metrics\n",
    "\n",
    "Name three different distance measures and briefly explain them. Check the metric axioms for one of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Hamming distance: the number of positions where two strings of equal length differ\n",
    "* Chebyshev distance (also: maximum distance): maximal absolute difference in a single coordinate.\n",
    "* p-norm: family of norms, defined by the formula $\\sqrt[p](\\sum_{i=1}^{L}|x_i-y_i|^p)$. Important special cases: city block (aka Manhattan, p=1), euclidean distance (p=2)\n",
    "* Jaccard distance: for binary attributes\n",
    "\n",
    "Metric axioms for Chebyshev distance $d(\\mathbf{x},\\mathbf{y}) := \\max_{i=1,\\ldots,L}|x_i-y_i|$:\n",
    "1. Symmetry: Here we use that the absolute value of the difference is symmetric: $|a-b| = |b-a|$, hence $d(\\mathbf{x},\\mathbf{y}) = \\max_{i=1,\\ldots,L}|x_i-y_i| = \\max_{i=1,\\ldots,L}|y_i-x_i| = d(\\mathbf{y},\\mathbf{x})$\n",
    "2. Coincidence (identity of indiscernibles): $d(\\mathbf{x},\\mathbf{x}) = \\max_{i=1,\\ldots,L}|x_i-x_i| = 0$\n",
    "3. Triangle equation: Here we apply that the triangle inequality holsd for the absolute value of the difference: $|a-c|+|c-b|\\geq|a-b|$, and hence\n",
    "\\begin{align}\n",
    "  d(\\mathbf{x},\\mathbf{z}) + d(\\mathbf{z},\\mathbf{y}) =\n",
    "\\max_{i=1,\\ldots,L}|x_i-z_i| + \\max_{i=1,\\ldots,L}|z_i-y_i| &\n",
    " \\geq \\max_{i=1,\\ldots,L}(|x_i-z_i| + |z_i-y_i|) \\\\\n",
    "& \\geq \\max_{i=1,\\ldots,L}(|x_i-y_i|) = d(\\mathbf{x},\\mathbf{y})\n",
    "\\end{align}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Mixture models\n",
    "\n",
    "What is a mixture model? Explain. Can you provide a formula?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A mixture model describes a two-step process to mix different (simple) data distributions. Such an approach can be used to model a large population with different subpopulations, each which individual characteristics.\n",
    "\n",
    "Formally, one provides a specific distribution $P(X\\mid Z=z)$ for every subpopulation $z$. These are mixed according to the probability $P(Z=z)$ to select an individual from that subpopulation, i.e.\n",
    "$$P(X=x) = \\sum_{z}P(Z=z)\\cdot P(X=x\\mid Z=z)$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 5: Dimension Reduction [2 Points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Visualization\n",
    "\n",
    "Name three different data visualization techniques to visualize high dimensional data. Explain one in detail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* a *scatterplot matrix* shows 2D projections of the data for all combination of axes\n",
    "* *Chernoff faces:* map parameters to facial features\n",
    "* *parallel coordinates:* map the different data dimensions to different x-coordinates and plot the corresponding values at the y-axis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) PCA\n",
    "\n",
    "Draw a few data points (ASCII arts or on a sheet of paper) and mark the principal components. What are the principal components?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Principal components form a set of linear independent vectors, pointing into the direction of the largest variance. Their length corresponds to the variance in that direction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Covariance matrix\n",
    "What does a covariance matrix express? How is it computed from data? How is it used in PCA?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The covariance matrix contains the covariance values for all pairs of coordinates. A positive covariance value means that high values for the first coordinate correspond to high values for the second coordinate. A negative covariance value expresses a correspondence of high values in the first coordinate with low values in the second coordinate. A value of $0$ means, that the values of the two coordinates do not correspond to each other.\n",
    "\n",
    "Given a set of $n$ data points in a $d$-dimensional data space as an $n\\times d$-matrix $D$, the covariance matrix is computed as $$C=(D-\\mu)^T\\cdot(D-\\mu)$$ where $\\mu$ denotes the mean vector of the data set.\n",
    "\n",
    "In PCA, the principal components are computed as eigenvectors of the covariance matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 6: Neural Networks [2 Points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Neural Networks\n",
    "\n",
    "Name three different kinds of Artificial Neural Networks discussed in the lecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The *multilayer perceptron* (MLP) consists of multiple layers of nodes through which activation is fed forward to compute an output vector to a given input pattern. It usually uses some non-linear activation function in each node and can be trained by a form of error gradient descent called back propagation.\n",
    "\n",
    "* A *radial basis function network* (RBFN) can be considered as a threee layer network: a given input pattern activates the hidden layer using a radial activation function. The output value is then determined as a linear combination of these values. In contrast to the MLP, the RBFN can be considered as a local classifier.\n",
    "\n",
    "* A *self-organizing map* (SOM) is a two layer architecture, in which a high-dimensional input space is connected to a low-dimension grid. The SOM learns a discretized, low dimension representation of the input data. In contrast to MLP and RBFN, the SOM is an unsupervised approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Backpropagation\n",
    "\n",
    "Which of the following formulae describes the backpropagation of the error through hidden layers in a Multilayer Perceptron?\n",
    "Assume they are calculated for each $k=L_H \\dots 1$ and $i=1\\dots N(k)$.\n",
    "\n",
    "1. $\\delta_i(k) = f^\\prime(o_i(k-1)) \\sum\\limits_{j=1}^{N(k+1)} w_{ji}(k+1, k)o_i(k)$\n",
    "2. $\\delta_i(k) = f^\\prime(o_i(k-1)) \\sum\\limits_{j=1}^{N(k+1)} w_{ji}(k+1, k)\\delta_i(k+1)$\n",
    "3. $\\delta_i(k) = f^\\prime(o_i(k-1)) \\sum\\limits_{j=1}^{N(k+1)} w_{ji}(k, k-1)\\delta_i(k+1)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Formula 1 uses the output instead of the deltas.\n",
    "* Formula 2 is correct. \n",
    "* Formula 3 uses the wrong weights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Hebb's rule\n",
    "Explain Hebb's rule. Provide a formula. What is the relation to Oja's rule?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea of Hebb's rule is to strengthen connections between neurons that fire simultanously. This is expressed by the formula\n",
    "$$\\Delta w_i = \\varepsilon y(\\vec{x}\\cdot\\vec{w})\\cdot x_i$$\n",
    "A high activation value $y(\\vec{x}\\cdot\\vec{w})$ coinciding with high values in the input $x_i$ results in a strong adaptation. \n",
    "\n",
    "Oja's rule is a modification of the standard Hebb Rule. It addresses the problem that the simple form of Hebb's rule does not allow the connection weights to decrease, so that they will eventually become arbitrarily large. Oja's rule avoids this problem by introducing some multiplicative normalization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 7: Local Methods [2 Points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Local methods\n",
    "\n",
    "What are differences between local and global methods? What are advantages or disadvantages?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A model is termed local, if the adaptation of model parameters only has local effects, i.e. it will only effect a subset of input values, located close to each other in the input space. In contrast, changing a parameter of a global model may effect all input values. Hence, local methods are considered to be more robust during training, as single (faulty) traning examples only effect a part of the system. Furthermore, such methods may be better to manage, as the effect of a single parameter is easier to understand."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) MLP and RBFN\n",
    "\n",
    "Is an MLP or are RBFN local methods? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RBFN are a local method as each hidden neuron has a local area of responsibility. In contrast, a MLP is global, as changing a single weight may change the input-output mapping for all input patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c)  Nearest neighbor\n",
    "\n",
    "How does the nearest neighbor approach work? How can it be improved?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In nearest neighbor learning, all training examples are stored in memory. Upon inference, when a new input is given, the most similar training example (the nearest neighbor) is retrieved and used to provide the result. In the $k$-nearest neighbor approach, not only one, but $k$ nearest neighbors are retrieved, and the result is determined by averaging over these values. A more advanced version uses a weighted average, including the distance of the neighbors from the given data point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 8: Classification [2 Points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Classfier\n",
    "\n",
    "What is a classifier? What is the relation to a concept?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A classifier assigns a class to an entity based on its attributes (attributes might be color, height, weight, shape, ..., classes might be car, house, person, banana, yes, ...). Formally, a classifier is a function $c:X\\to C$ that assigns a class $c(x)\\in C$ to every object $x\\in X$. Hence, a concept is a special classifier with only two classes $C=\\{\\operatorname{true},\\operatorname{false}\\}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Comparison of classifiers\n",
    "\n",
    "Name three different classifiers and compare them. Think about biases and assumptions, separatrices, sensitivity, locality, parameters and speed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Usually assuming 0 mean and only binary problems!*\n",
    "\n",
    "| Classifier           | Biases and Assumptions | Separatrices | Sensitivity | Locality | Parameters | Speed |\n",
    "|----------------------|------------------------|--------------|-------------|----------|------------|-------|\n",
    "| Euclidean classifier | voronoi tesselation around class centers | linear | sensitive to far outliers | global | none | very fast |\n",
    "| Linear discriminant analysis | normally distributed data with equal covariances | linear | sensitive to far outliers | global | none | very fast |\n",
    "| Quadratic classifier (e.g. QDA) | ? | conic: e.g. hyperbola, parabola, ellipsis, line | sensitive to outliers | global | none | fast |\n",
    "| Polynom classifier | ? | almost arbitrary | overfitting for high degrees | global | polynomial degree | fast |\n",
    "| Nearest neighbor classifier  | classification for neighbors are similar | implicit: neighbors (voronoi cells around training data) | distance function | local | number of neighbors $k$ | $\\mathcal{O}(N)$ (instant training, linear classification) |\n",
    "| Bayesian classifier | expected cost is minimized | discriminate functions (probability distributions) | overlapping classifications (only probabilities), noise is modeled | global | none | varies (underlying data and method for discriminate functions, see ML-09 Slides 5f) |\n",
    "| MLP (not necessarily binary) | smooth interpolation | almost arbitrary | noise sensitive | global | activation functions, learning rate | slow |\n",
    "| RBFN (not necessarily binary) | locality in data/clusters | ellipses/circular | robust to noise | local | regions of responsibility,  learning rate | comparably slow |\n",
    "| SVM | mercer's condition, input mapping, kernel function | high dimensional hyperplane, nonlinear in data space | handles noise with slacking variables | global | none | efficient |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) SVM\n",
    "\n",
    "What is a support vector? How does the kernel trick work?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a two part dataset, the support vectors are those vectors of each class, that are closest to vectors from the other class. Then the separatrix is computed as the hyperplane with maximal distance to these support vectors.\n",
    "\n",
    "In many cases, two classes can not be separated by a simple hyperplane. However, often one can find an embedding of the data into a higher-dimensional space where it becomes linearly separable. The kernel trick uses the fact, that for many tasks one does not have to compute the embedding explicitly, but it suffices to be able to compute the inner product of embedded datapoints, using an appropriate *kernel function*. This trick is most prominently used in support vector based classification, but it can also be used for other tasks like clustering and PCA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 9: Reinforcement Learning [2 Points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a)\n",
    "\n",
    "What is an agent in terms of reinforcement learning? Name an example of an agent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An agent has sensors and can perform actions in a specified environment. (See PEAS: Performance, Environment, Actuators, Sensors)\n",
    "\n",
    "Some possible agents are: mobile robots or game AI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b)\n",
    "\n",
    "What is the Markov assumption? How is it related to Q-learning? Give an example for which it does not hold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The (first-order) Markov assumption means that state $s_{t+1}$ only depends on its predecessor state $s_t$ and the action $a_t$ performed then, i.e.: $s_{t+1} = \\delta(s_t, a_t)$. This allows to specify a $Q$-function of the form $Q(s_t,a_t)$, instead of $Q(s_0,a_0,\\ldots,s_t,a_t)$. The Markov assumption does not hold in situations where, e.g. the state does contain full information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) \n",
    "What does the $Q$-function express in reinforcement learning and how is it used?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The $Q$-function provides the (discounted) maximal cummulative reward for performing an action $a$ in state $s$. The $Q$-function can be stated in a recursive form as\n",
    "$$Q(s,a) = r(s,a) + \\gamma\\cdot\\max_{a'\\in\\operatorname{Actions}(s)}{Q(\\delta(s,a),a')}.$$\n",
    "with $\\gamma$ being the discount factor.\n",
    "The $Q$-function can be used to define an optimal action selection policy for a reinforcement learning problem by\n",
    "$$a^{\\ast}(s) = \\operatorname{argmax}_{a\\in\\operatorname{Actions}(s)}Q(s,a)$$\n",
    "In $Q$-learning the $Q$-function is approximated by an iterative procedure.\n",
    "\n",
    "Remark: There is no relation of the $Q$-function of reinforcement learning and the $Q$-function in the EM algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 10: Modeling Uncertainty [2 Points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Uncertainty\n",
    "\n",
    "Why do we need to model uncertainties?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncertainty can occur due to many reasons:\n",
    "* sparse data\n",
    "* unreliable data (noise)\n",
    "* uncertain outcomes\n",
    "* high complexities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Naive Bayes\n",
    "\n",
    "What is a naive Bayes classifier? Why is it naive? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes is a probabilistic classifier, i.e. a classifier that instead of a class assignment $x\\mapsto c(x)\\in C$ provides a probability value $P(C=c\\mid X=x)$. The naive Bayes classifier applies Bayes theorem to compute the posterior (diagnostical) probability $P(C\\mid X)$ from likelihood values $P(X\\mid C)$ (and prior $P(X)$) that have been learned from training data. Naivity refers to the simplifying assumption that the different features $X_1,\\ldots,X_n$ are conditional independent, given the class $C$, an assumption that may not be true in general but proves to work well in many applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### c) Probabilities\n",
    "\n",
    "Given the following table, calculate the probability of drawing a blue candy blindly (assume the bags are chosen equally likely). Then calculate the probability that our drawn blue candy was drawn from the red bag.\n",
    "\n",
    "|                | blue candies | green candies |\n",
    "|----------------|--------------|---------------|\n",
    "| **red bag**    |            5 |            10 |\n",
    "| **yellow bag** |           20 |            10 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P(C=b) = \\frac{1}{2} \\left( \\frac{5}{15} + \\frac{20}{30} \\right) = \\frac{1}{2}$$\n",
    "$$P(B=r|C=b) = \\frac{P(C=b|B=r)P(B=r)}{P(C=b)} = \\frac{ \\frac{5}{15} \\frac{1}{2} }{ \\frac{1}{2} } = \\frac{5}{15} = \\frac{1}{3}$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
