{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OsnabrÃ¼ck University - Machine Learning (Summer Term 2016) - Prof. Dr.-Ing. G. Heidemann, Ulf Krumnack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise Sheet 08"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This week's sheet should be solved and handed in before the end of **Sunday, June 12, 2016**. If you need help (and Google and other resources were not enough), feel free to contact your groups' designated tutor or whomever of us you run into first. Please upload your results to your group's Stud.IP folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 1: Multilayer Perceptron (MLP) [10 Points]\n",
    "\n",
    "Last week you implemented a simple perceptron. This week we already provide some basic perceptron which you will adjust to build network from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Generate some data.\n",
    "N = 1000\n",
    "input_dim = 3\n",
    "D = np.random.rand(N, input_dim)\n",
    "# Label data: sum should be > 0.8 * dim.\n",
    "T = (np.sum(D, 1) > 0.8 * input_dim) * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "def train_perceptron(perceptron, D, T, epochs, sample_size, verbose=True):\n",
    "    \"\"\"\n",
    "    Trains the perceptron over epochs epochs with sample_size \n",
    "    random samples drawn from D. No replacement is done in one epoch.\n",
    "    \n",
    "    Args:\n",
    "        perceptron  The perceptron. Must implement a function\n",
    "                    adaption(X, t) where X is a row of D and t\n",
    "                    is its label.\n",
    "        D           The data of size N x d where N is the\n",
    "                    number of samples and d is the number\n",
    "                    of dimensions.\n",
    "        T           The training labels. Iterable with\n",
    "                    N x do elements where N is the number\n",
    "                    of samples in D and do is the dimension\n",
    "                    of the perceptrons output.    \n",
    "        epochs      The number of training epochs.\n",
    "        sample_size The number of random samples per epoch.\n",
    "        verbose     Prints status messages if True (default).\n",
    "    \"\"\"\n",
    "    if verbose:\n",
    "        print('Training {}\\nEpochs: {}\\nSamples per Epoch: {}'.format(perceptron, epochs, sample_size))\n",
    "    for epoch in range(epochs):\n",
    "        if verbose:\n",
    "            sys.stdout.write(\"\\rEpoch {:5d}, {:7.2%}\".format(epoch + 1, (epoch + 1) / epochs))\n",
    "            sys.stdout.flush()\n",
    "        sample_indices = np.random.choice(range(N), sample_size, replace=False)\n",
    "        for index in sample_indices:\n",
    "            x = D[index]\n",
    "            t = T[index]\n",
    "            perceptron.adaption(x, t)\n",
    "    if verbose:\n",
    "        print('\\nFinished.')\n",
    "\n",
    "def test_perceptron(perceptron, D, T, verbose=True):\n",
    "    \"\"\"\n",
    "    Tests the perceptron on all provided data.\n",
    "    \n",
    "    Args:\n",
    "        perceptron  The perceptron. Must implement a function\n",
    "                    activation(X) where X is a row of D.\n",
    "        D           The data of size N x d where N is the\n",
    "                    number of samples and d is the number\n",
    "                    of dimensions.\n",
    "        T           The training labels. Iterable with\n",
    "                    N x do elements where N is the number\n",
    "                    of samples in D and do is the dimension\n",
    "                    of the perceptrons output.\n",
    "        verbose     Prints status messages if True (default).\n",
    "    Returns:\n",
    "        The absolute error per output component.\n",
    "    \"\"\"\n",
    "    if verbose:\n",
    "        print('Testing {}'.format(perceptron))\n",
    "    error = 0\n",
    "    for i, t in enumerate(T):\n",
    "        error += np.abs(t - perceptron.activation(D[i])) / len(D)\n",
    "    if verbose:\n",
    "        print('Total error:', error)\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class BasePerceptron:\n",
    "    \"\"\"\n",
    "    A simple perceptron implementation.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dimensions=100, epsilon=0.03):\n",
    "        \"\"\"\n",
    "        Initializes the perceptron. Creates dimensions + 1\n",
    "        random weights (the additional weight is the bias.)\n",
    "\n",
    "        Args:\n",
    "            dimensions  the data dimensionality N\n",
    "            epsilon     the learning rate\n",
    "        \"\"\"\n",
    "        self.w = np.zeros(dimensions + 1)#np.random.rand(dimensions + 1)\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def activation(self, X):\n",
    "        \"\"\"\n",
    "        The activation function. Prepends a 1 to X for the\n",
    "        bias and calculates the activation function of the \n",
    "        perceptron.\n",
    "\n",
    "        Args:\n",
    "            X   the data point, should be a numpy\n",
    "                array or a 1xN numpy matrix\n",
    "        Returns:\n",
    "            1   if the activation of X is bigger than 0\n",
    "            0   else\n",
    "        \"\"\"\n",
    "        return 1 if np.append(1, X) @ self.w > 0 else 0\n",
    "\n",
    "    def adaption(self, X, t):\n",
    "        \"\"\"\n",
    "        Trains the perceptron. Adjusts the weights according to \n",
    "        the learning rate and the error between the activation and the \n",
    "        label (delta).\n",
    "\n",
    "        Args:\n",
    "            X   the data point, should be a numpy\n",
    "                array or a 1xN numpy matrix\n",
    "            t   the label\n",
    "        \"\"\"\n",
    "        self.w += self.epsilon * (t - self.activation(X)) * np.append(1, X)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '{}({}, {})'.format(self.__class__.__name__, len(self.w) - 1, self.epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training BasePerceptron(3, 0.03)\n",
      "Epochs: 20\n",
      "Samples per Epoch: 100\n",
      "Epoch    20, 100.00%\n",
      "Finished.\n",
      "Testing BasePerceptron(3, 0.03)\n",
      "Total error: 0.011\n"
     ]
    }
   ],
   "source": [
    "# Instantiate a perceptron.\n",
    "epsilon = 0.03\n",
    "perceptron = BasePerceptron(input_dim, epsilon)\n",
    "\n",
    "# Train and test the perceptron.\n",
    "train_perceptron(perceptron, D, T, epochs=20, sample_size=100)\n",
    "_ = test_perceptron(perceptron, D, T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class InputPerceptron(BasePerceptron):\n",
    "    \"\"\"\n",
    "    InputPerceptron inherits all properties of the \n",
    "    BasePerceptron but implements a new activation function:\n",
    "    Instead of just using a threshold, it ignores its \n",
    "    weights and just passes on its input.\n",
    "    \"\"\"\n",
    "\n",
    "    def activation(self, X):\n",
    "        \"\"\"\n",
    "        The activation function for input perceptrons is\n",
    "        the identity function.\n",
    "\n",
    "        Args:\n",
    "            X           the data point\n",
    "        Returns:\n",
    "            X\n",
    "        \"\"\"\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.special\n",
    "\n",
    "class ContinuousPerceptron(BasePerceptron):\n",
    "    \"\"\"\n",
    "    ContinuousPerceptron inherits all properties of the \n",
    "    BasePerceptron but implements a new activation function:\n",
    "    Instead of just using a threshold, the continuous perceptron\n",
    "    uses a sigmoid function.\n",
    "    \"\"\"\n",
    "\n",
    "    def activation(self, X):\n",
    "        \"\"\"\n",
    "        The activation function. Prepends a 1 to X for the\n",
    "        bias and calculates the activation function of the \n",
    "        perceptron.\n",
    "\n",
    "        Args:\n",
    "            X           the data point, should be a numpy\n",
    "                        array or a 1xN numpy matrix\n",
    "        Returns:\n",
    "            1 / (1 + exp( -y ))\n",
    "            where y is the dot product of the weights and \n",
    "            the padded input.\n",
    "        \"\"\"\n",
    "        return scipy.special.expit(self.w @ np.append(1, X))\n",
    "\n",
    "    def adaption(self, X, t):\n",
    "        \"\"\"\n",
    "        Trains the perceptron. Adjusts the weights according to \n",
    "        the learning rate and the error between the activation and the \n",
    "        label (delta).\n",
    "\n",
    "        Args:\n",
    "            X   the data point, should be a numpy\n",
    "                array or a 1xN numpy matrix\n",
    "            t   the delta\n",
    "        \"\"\"\n",
    "        self.w += self.epsilon * t * np.append(1, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class MultiLayerPerceptron:\n",
    "    def __init__(self, dimensions=[2, 1, 1], epsilon=0.03):\n",
    "        self.layers = []\n",
    "        self.epsilon = epsilon\n",
    "        \n",
    "        # Create input layer.\n",
    "        self.layers.append([InputPerceptron(1, 0) for i in range(dimensions[0])])\n",
    "        \n",
    "        # Generate hidden and output layers.\n",
    "        dim = len(self.layers[0])\n",
    "        for N in dimensions[1:]:\n",
    "            layer = [ContinuousPerceptron(dim, epsilon) for i in range(N)]\n",
    "            self.layers.append(layer)\n",
    "            dim = N\n",
    "        \n",
    "        # Initialize outputs and deltas.\n",
    "        self.outputs = []\n",
    "        self.deltas = []\n",
    "\n",
    "    def activation(self, X):\n",
    "        \"\"\"\n",
    "        Feed forward activation.\n",
    "        \"\"\"\n",
    "        # Clear potentially stored outputs.\n",
    "        self.outputs = []\n",
    "        \n",
    "        # Activate input layer and store its outputs.\n",
    "        layer_outputs = np.array([self.layers[0][i].activation(x) for i, x in enumerate(X)])\n",
    "        self.outputs.append(layer_outputs)\n",
    "\n",
    "        # Activate all other layers with the outputs from before.\n",
    "        for layer in self.layers[1:]:\n",
    "            layer_outputs = np.array([layer[j].activation(layer_outputs) for j in range(len(layer))])\n",
    "            self.outputs.append(layer_outputs)\n",
    "\n",
    "        # Return the last outputs for the output layer.\n",
    "        return np.copy(layer_outputs)\n",
    "\n",
    "    def adaption(self, X, t):\n",
    "        \"\"\"\n",
    "        Backpropagation adaption.\n",
    "        \"\"\"\n",
    "        from pprint import pprint\n",
    "        print()\n",
    "        print('X',X)\n",
    "        print('t',t)\n",
    "        # Clear potentially stored deltas.\n",
    "        self.deltas = []\n",
    "        \n",
    "        # Activate perceptron to figure out and store each\n",
    "        # neuron's output.\n",
    "        outputs = self.activation(X)\n",
    "        \n",
    "        # Compute error:\n",
    "        error = (t - outputs)\n",
    "        print('error',error)\n",
    "        \n",
    "        print('Outputs')\n",
    "        pprint(self.outputs)\n",
    "        \n",
    "        # Calculate deltas for output layer and store them.\n",
    "        layer_deltas = outputs * (1 - outputs) * error\n",
    "        self.deltas.insert(0, layer_deltas)\n",
    "        \n",
    "        # Calculate other deltas.\n",
    "        for k in range(len(self.layers) - 2, 0, -1):\n",
    "            layer_deltas = []\n",
    "            for i, neuron in enumerate(self.layers[k]):\n",
    "                sigma = self.outputs[k][i] * (1 - self.outputs[k][i])\n",
    "                delta = self.deltas[0]\n",
    "                w = np.array([j.w[i] for j in self.layers[k + 1]])\n",
    "                n_delta = sigma * w @ delta\n",
    "                print(sigma, delta, w, n_delta)\n",
    "                layer_deltas.append(n_delta)\n",
    "            print(layer_deltas)\n",
    "            self.deltas.insert(0, np.array(layer_deltas))\n",
    "\n",
    "        print('deltas')\n",
    "        pprint(self.deltas)\n",
    "        # Adapt weights for hidden and output neurons.\n",
    "        for k, layer in enumerate(self.layers[1:]):\n",
    "            for i, neuron in enumerate(layer):\n",
    "                neuron.adaption(self.outputs[k], self.deltas[k][i])\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return 'MultiLayerPerceptron({}, {})'.format([len(l) for l in self.layers], self.epsilon)\n",
    "\n",
    "    def __str__(self):\n",
    "        return '\\n\\t'.join([repr(self)] + [str(l) for l in self.layers])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "X [ 0.09951099  0.40638386  0.61842743]\n",
      "t 0\n",
      "error [-0.5]\n",
      "Outputs\n",
      "[array([ 0.09951099,  0.40638386,  0.61842743]),\n",
      " array([ 0.5,  0.5,  0.5]),\n",
      " array([ 0.5,  0.5]),\n",
      " array([ 0.5])]\n",
      "0.25 [-0.125] [ 0.] -0.0\n",
      "0.25 [-0.125] [ 0.] -0.0\n",
      "[-0.0, -0.0]\n",
      "0.25 [-0. -0.] [ 0.  0.] 0.0\n",
      "0.25 [-0. -0.] [ 0.  0.] 0.0\n",
      "0.25 [-0. -0.] [ 0.  0.] 0.0\n",
      "[0.0, 0.0, 0.0]\n",
      "deltas\n",
      "[array([ 0.,  0.,  0.]), array([-0., -0.]), array([-0.125])]\n",
      "1 0\n",
      "[ 0.09951099  0.40638386  0.61842743]\n",
      "0.0\n",
      "1 1\n",
      "[ 0.09951099  0.40638386  0.61842743]\n",
      "0.0\n",
      "1 2\n",
      "[ 0.09951099  0.40638386  0.61842743]\n",
      "0.0\n",
      "2 0\n",
      "[ 0.5  0.5  0.5]\n",
      "-0.0\n",
      "2 1\n",
      "[ 0.5  0.5  0.5]\n",
      "-0.0\n",
      "3 0\n",
      "[ 0.5  0.5]\n",
      "-0.125\n",
      "\n",
      "X [ 0.90325242  0.67528833  0.29493246]\n",
      "t 0\n",
      "error [-0.49859375]\n",
      "Outputs\n",
      "[array([ 0.90325242,  0.67528833,  0.29493246]),\n",
      " array([ 0.5,  0.5,  0.5]),\n",
      " array([ 0.5,  0.5]),\n",
      " array([ 0.49859375])]\n",
      "0.25 [-0.12464745] [-0.00375] 0.000116856986666\n",
      "0.25 [-0.12464745] [-0.001875] 5.84284933329e-05\n",
      "[0.00011685698666582227, 5.8428493332911134e-05]\n",
      "0.25 [  1.16856987e-04   5.84284933e-05] [ 0.  0.] 0.0\n",
      "0.25 [  1.16856987e-04   5.84284933e-05] [ 0.  0.] 0.0\n",
      "0.25 [  1.16856987e-04   5.84284933e-05] [ 0.  0.] 0.0\n",
      "[0.0, 0.0, 0.0]\n",
      "deltas\n",
      "[array([ 0.,  0.,  0.]),\n",
      " array([  1.16856987e-04,   5.84284933e-05]),\n",
      " array([-0.12464745])]\n",
      "1 0\n",
      "[ 0.90325242  0.67528833  0.29493246]\n",
      "0.0\n",
      "1 1\n",
      "[ 0.90325242  0.67528833  0.29493246]\n",
      "0.0\n",
      "1 2\n",
      "[ 0.90325242  0.67528833  0.29493246]\n",
      "0.0\n",
      "2 0\n",
      "[ 0.5  0.5  0.5]\n",
      "0.000116856986666\n",
      "2 1\n",
      "[ 0.5  0.5  0.5]\n",
      "5.84284933329e-05\n",
      "3 0\n",
      "[ 0.5  0.5]\n",
      "-0.124647452444\n"
     ]
    }
   ],
   "source": [
    "# Instantiate a multilayer perceptron.\n",
    "epsilon = 0.03\n",
    "output_dim = 1\n",
    "layers = [input_dim, 3, 2, output_dim]\n",
    "perceptron = MultiLayerPerceptron(layers, epsilon)\n",
    "\n",
    "# Train and test the perceptron.\n",
    "# train_perceptron(perceptron, D, T, epochs=20, sample_size=100)\n",
    "train_perceptron(perceptron, D, T, epochs=1, sample_size=2, verbose=False)\n",
    "# _ = test_perceptron(perceptron, D, T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 2: MLP and RBFN [10 Points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
