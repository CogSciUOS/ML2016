{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OsnabrÃ¼ck University - Machine Learning (Summer Term 2016) - Prof. Dr.-Ing. G. Heidemann, Ulf Krumnack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise Sheet 08"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This week's sheet should be solved and handed in before the end of **Sunday, June 12, 2016**. If you need help (and Google and other resources were not enough), feel free to contact your groups' designated tutor or whomever of us you run into first. Please upload your results to your group's Stud.IP folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 1: Multilayer Perceptron (MLP) [10 Points]\n",
    "\n",
    "Last week you implemented a simple perceptron. This week we already provide some basic perceptron which you will adjust to build network from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The perceptron classifies 99.20% of the data correctly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class SimplePerceptron:\n",
    "    \"\"\"\n",
    "    A simple perceptron implementation.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dimensions=100, epsilon=0.03):\n",
    "        \"\"\"\n",
    "        Initializes the perceptron. Creates dimensions + 1\n",
    "        random weights (the additional weight is the bias.)\n",
    "\n",
    "        Args:\n",
    "            dimensions  the data dimensionality N\n",
    "            epsilon     the learning rate\n",
    "        \"\"\"\n",
    "        self.w = np.random.rand(dimensions + 1)\n",
    "        self.epsilon = epsilon\n",
    "        \n",
    "    def activation(self, X):\n",
    "        \"\"\"\n",
    "        The activation function. Prepends a 1 to X for the\n",
    "        bias and calculates the activation function of the \n",
    "        perceptron.\n",
    "\n",
    "        Args:\n",
    "            X           the data point, should be a numpy\n",
    "                        arary or a 1xN numpy matrix\n",
    "\n",
    "        Returns:\n",
    "            True  if the activation of X is bigger than 0\n",
    "            False elseal\n",
    "        \"\"\"\n",
    "        return np.append(1, X) @ self.w > 0\n",
    "\n",
    "    def train(self, X, t):\n",
    "        \"\"\"\n",
    "        Trains the perceptron. Adjusts the weights according to \n",
    "        the learning rate and the error between the activation and t.\n",
    "\n",
    "        Args:\n",
    "            X           the data point, should be a numpy\n",
    "                        arary or a 1xN numpy matrix\n",
    "            t           the label for this data point should be\n",
    "                        True or False\n",
    "        \"\"\"\n",
    "        self.w += self.epsilon * (t - self.activation(X)) * np.append(1, X)\n",
    "\n",
    "# Generate some data.\n",
    "N = 1000\n",
    "dim = 3\n",
    "D = np.random.rand(1000, dim)\n",
    "# Label data: sum should be > 0.8 * dim\n",
    "D = np.hstack((D, np.matrix(np.sum(D, 1) > 0.8 * dim).T))\n",
    "\n",
    "# Instantiate a Perceptron.\n",
    "perceptron = SimplePerceptron(D.shape[1] - 1)\n",
    "\n",
    "# Train the perceptron for several epochs.\n",
    "epochs = 20\n",
    "sample_size = 100\n",
    "for epoch in range(epochs):\n",
    "    for sample in range(sample_size):\n",
    "        sample_data = D[np.random.choice(range(N), replace=False),:]\n",
    "        for data in sample_data:\n",
    "            x = data[0,0:-1]\n",
    "            t = data[0,-1]\n",
    "            perceptron.train(x, t)\n",
    "\n",
    "# Test the perceptron on all data.\n",
    "error = 0\n",
    "for data in D:\n",
    "    error += np.abs(data[0,-1] - perceptron.activation(data[0,0:-1])) / N\n",
    "print(\"The perceptron classifies {:.2%} of the data correctly.\".format(1 - error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "class Perceptron:\n",
    "    def __init__(self, dimensions=100, epsilon=0.03):\n",
    "        self.w = np.random.rand(dimensions + 1)\n",
    "        self.epsilon = epsilon\n",
    "        self.y = None\n",
    "        self.delta_fun = None\n",
    "\n",
    "    def activation(self, X):\n",
    "        self.y = self.w @ np.append(1, X)\n",
    "        return self.y\n",
    "\n",
    "def d_expit(x):\n",
    "    s_y = scipy.special.expit(y)\n",
    "    return s_y * (1 - s_y)\n",
    "    \n",
    "def delta_fun_out(t, y):\n",
    "    return (t - y) * d_expit(y)\n",
    "\n",
    "def delta_fun_hidden(W, D, y):\n",
    "    return W @ D * d_expit(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MultiLayerPerceptron:\n",
    "    def __init__(self, neurons_per_layer):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 2: MLP and RBFN [10 Points]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
