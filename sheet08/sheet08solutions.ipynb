{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OsnabrÃ¼ck University - Machine Learning (Summer Term 2016) - Prof. Dr.-Ing. G. Heidemann, Ulf Krumnack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise Sheet 08"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This week's sheet should be solved and handed in before the end of **Sunday, June 12, 2016**. If you need help (and Google and other resources were not enough), feel free to contact your groups' designated tutor or whomever of us you run into first. Please upload your results to your group's Stud.IP folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 1: Multilayer Perceptron (MLP) [10 Points]\n",
    "\n",
    "Last week you implemented a simple perceptron. This week we already provide some basic perceptron which you will adjust to build network from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "class SimplePerceptron:\n",
    "    \"\"\"\n",
    "    A simple perceptron implementation.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dimensions=100, epsilon=0.03):\n",
    "        \"\"\"\n",
    "        Initializes the perceptron. Creates dimensions + 1\n",
    "        random weights (the additional weight is the bias.)\n",
    "\n",
    "        Args:\n",
    "            dimensions  the data dimensionality N\n",
    "            epsilon     the learning rate\n",
    "        \"\"\"\n",
    "        self.w = np.random.rand(dimensions + 1)\n",
    "        self.epsilon = epsilon\n",
    "        \n",
    "    def activation(self, X):\n",
    "        \"\"\"\n",
    "        The activation function. Prepends a 1 to X for the\n",
    "        bias and calculates the activation function of the \n",
    "        perceptron.\n",
    "\n",
    "        Args:\n",
    "            X           the data point, should be a numpy\n",
    "                        arary or a 1xN numpy matrix\n",
    "\n",
    "        Returns:\n",
    "            True  if the activation of X is bigger than 0\n",
    "            False elseal\n",
    "        \"\"\"\n",
    "        return np.append(1, X) @ self.w > 0\n",
    "\n",
    "    def train(self, X, t):\n",
    "        \"\"\"\n",
    "        Trains the perceptron. Adjusts the weights according to \n",
    "        the learning rate and the error between the activation and t.\n",
    "\n",
    "        Args:\n",
    "            X           the data point, should be a numpy\n",
    "                        arary or a 1xN numpy matrix\n",
    "            t           the label for this data point should be\n",
    "                        True or False\n",
    "        \"\"\"\n",
    "        self.w += self.epsilon * (t - self.activation(X)) * np.append(1, X)\n",
    "\n",
    "# Generate some data.\n",
    "N = 1000\n",
    "dim = 3\n",
    "D = np.random.rand(1000, dim)\n",
    "# Label data: sum should be > 0.8 * dim\n",
    "D = np.hstack((D, np.matrix(np.sum(D, 1) > 0.8 * dim).T))\n",
    "\n",
    "# Instantiate a Perceptron.\n",
    "perceptron = SimplePerceptron(D.shape[1] - 1)\n",
    "\n",
    "# Train the perceptron for several epochs.\n",
    "epochs = 20\n",
    "sample_size = 100\n",
    "for epoch in range(epochs):\n",
    "    for sample in range(sample_size):\n",
    "        sample_data = D[np.random.choice(range(N), replace=False),:]\n",
    "        for data in sample_data:\n",
    "            x = data[0,0:-1]\n",
    "            t = data[0,-1]\n",
    "            perceptron.train(x, t)\n",
    "\n",
    "# Test the perceptron on all data.\n",
    "error = 0\n",
    "for data in D:\n",
    "    error += np.abs(data[0,-1] - perceptron.activation(data[0,0:-1])) / N\n",
    "print(\"The perceptron classifies {:.2%} of the data correctly.\".format(1 - error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "\n",
    "    def __init__(self, dimensions=100, epsilon=0.03):\n",
    "        self.w = np.random.rand(dimensions + 1)\n",
    "        self.epsilon = epsilon\n",
    "        self.y = None\n",
    "\n",
    "    def activation(self, X):\n",
    "        self.y = ...\n",
    "        return self.y\n",
    "\n",
    "    def train(self, X, t, delta):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MultiLayerPerceptron:\n",
    "    def __init__(self, neurons_per_layer):\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 2: MLP and RBFN [10 Points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "This exercise is aimed at deepening the understanding of Radial Basis Function Networks and how they relate to Multilayer Perceptrons. Not all of the answers can be found directly in the slides - so when answering the (more algorithmic) questions, first take a minute and think about how you would go about solving them and if nothing comes to mind search the internet for a little bit. If you are interested in a real life application of both algorithms and how they compare take a look at this paper: [Comparison between Multi-Layer Perceptron and Radial Basis Function Networks for Sediment Load Estimation in a Tropical Watershed](http://file.scirp.org/pdf/JWARP20121000014_80441700.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Radial Basis Function Networks\n",
    "\n",
    "![Schematic of a RBFN](RBFN.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are radial basis functions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the structure of a RBFN? You may also use the notion from the above included picture."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How would one initialize such a network? (Hint: make use of other algorithms already covered in the lecture)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How is a RBFN trained?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison to the Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How can classification in both networks be visualized?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When would you use a RBFN instead of a Multilayer Perceptron?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
