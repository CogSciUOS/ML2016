{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Osnabrück University - Machine Learning (Summer Term 2016) - Prof. Dr.-Ing. G. Heidemann, Ulf Krumnack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise Sheet 02: Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 1: Decision Trees\n",
    "Draw the decision trees for the following boolean functions. Either use pen and paper or employ your ASCII artist within below. \n",
    "\n",
    "Note: $\\oplus := xor$, that means one of the operands has to be true, while the other one has to be false:\n",
    "\n",
    "$\\oplus$ | $B$ | $\\neg B$\n",
    "---------|-----|---------\n",
    "$A$      |  f  |    t\n",
    "$\\neg A$ |  t  |    f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) $\\neg A \\wedge B$"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "     A\n",
    "    / \\\n",
    " t /   \\ f\n",
    "  /     \\\n",
    " No      B\n",
    "        / \\\n",
    "     t /   \\ f\n",
    "      /     \\\n",
    "    Yes     No"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) $A \\oplus B$ "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "           A\n",
    "          / \\\n",
    "     t  /     \\  f\n",
    "      /         \\\n",
    "     B           B\n",
    "    / \\         / \\\n",
    " t /   \\ f   t /   \\ f\n",
    "  /     \\     /     \\\n",
    " No     Yes Yes     No"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) $A \\vee (B \\wedge C) \\vee (\\neg C \\wedge D)$"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "        A\n",
    "       / \\\n",
    "  t  /     \\  f\n",
    "   /         \\\n",
    " Yes          C\n",
    "             / \\\n",
    "        t  /     \\  f\n",
    "         /         \\\n",
    "        B           D\n",
    "       / \\         / \\\n",
    "    t /   \\ f   t /   \\ f\n",
    "     /     \\     /     \\\n",
    "   Yes     No   No     Yes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d) $(A \\rightarrow (B \\wedge \\neg C)) \\vee (A \\wedge B)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "$= (\\neg A \\vee (B \\wedge \\neg C)) \\vee (A \\wedge B)$\n",
    "\n",
    "$= \\neg A \\vee (A \\wedge B) \\vee (B \\wedge \\neg C)$\n",
    "\n",
    "$= \\neg A \\vee (A \\wedge B)$"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "          A\n",
    "         / \\\n",
    "      t /   \\ f\n",
    "       /     \\\n",
    "      B      Yes\n",
    "     / \\\n",
    "  t /   \\ f\n",
    "   /     \\\n",
    " Yes     No"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 2: Entropy and Information Gain\n",
    "\n",
    "Attributes and their possible values:\n",
    "\n",
    "  * $raining = \\{yes, no\\}$\n",
    "  * $tired = \\{yes, no\\}$\n",
    "  * $late = \\{yes, no\\}$\n",
    "  * $distance = \\{short, medium, long\\}$\n",
    "\n",
    "Training examples:\n",
    "\n",
    "| #  | raining | tired | late | distance | attend_party |\n",
    "|----|---------|-------|------|----------|--------------|\n",
    "| 1  | yes | no  | no  | short  | **yes** |\n",
    "| 2  | yes | no  | yes | medium | **no**  |\n",
    "| 3  | no  | yes | no  | long   | **no**  |\n",
    "| 4  | yes | yes | yes | short  | **no**  |\n",
    "| 5  | yes | no  | no  | short  | **yes** |\n",
    "| 6  | no  | no  | no  | medium | **yes** |\n",
    "| 7  | no  | yes | no  | long   | **no**  |\n",
    "| 8  | yes | no  | yes | short  | **no**  |\n",
    "| 9  | yes | yes | no  | short  | **yes** |\n",
    "| 10 | no  | yes | no  | medium | **no**  |\n",
    "| 11 | no  | yes | no  | long   | **no**  |\n",
    "| 12 | no  | yes | yes | short  | **no**  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a)\n",
    "Build the root node of a decision tree from the training examples given in the table above by calculate the information gain on all four attributes (raining, tired, late, distance).\n",
    "\n",
    "$$Gain(S,A) = Entropy(S) - \\sum_{v \\in Values(A)} \\frac{|S_v|}{|S|}Entropy(S_v)$$\n",
    "$$Entropy(S) = -p_{\\oplus} log_{2} p_{\\oplus} - p_{\\ominus} log_{2} p_{\\ominus}$$\n",
    "\n",
    "\n",
    "\n",
    "$S_v$ is the subset of $S$ for which attribute A has value v. Example for attribute *tired*:\n",
    "$S_{yes} \\leftarrow [1+, 6−], |S_{yes}| = 7 \\quad \\quad \\quad S_{no} \\leftarrow [3+, 2−], |S_{no}| = 5$"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b)\n",
    "Perform the same calculation as in **a)** but use the gain ratio instead of the information gain. Does the result for the root node change?\n",
    "\n",
    "$$GainRatio(S,A) = \\frac{Gain(S,A)}{SplitInformation(S,A)}$$\n",
    "$$SplitInformation(S,A) = - \\sum_{v \\in Values(A)} \\frac{|S_v|}{|S|} log_{2} \\frac{S_{v}}{S}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c)\n",
    "Let’s assume the root node is a node which checks the value of the attribute has *distance*. Calculate the next level of the decision tree using the information gain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 3\n",
    "Implement the following two functions in Python. Take a look at the `assert`s to see how the function should behave. An assert is a condition that your function is required to pass. Most of the conditions here are taken from the lecture slides (ML-03, Slide 12 & 13). Don't worry if you do not get all asserts to pass, just comment them out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Entropy\n",
    "$$Entropy(S) = - \\sum_{i=1...c} p_i log_2 p_i$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from math import log\n",
    "def entropy(S):\n",
    "    \"\"\"\n",
    "    Calculate the entropy for a given target value set. \n",
    "    S: List of target classes for specific observations.\n",
    "    \"\"\"\n",
    "    p_i = [len([value for value in S if value == c])/len(S) for c in set(S)]\n",
    "    return - sum(p * log(p, 2) for p in p_i) \n",
    "\n",
    "\n",
    "# See ML-03, Slide 12 & 13\n",
    "assert entropy([1,1,1,0,0,0]) == 1.0\n",
    "assert round(entropy([1,1,1,1,0,0,0]), 3) == 0.985\n",
    "assert round(entropy([1,1,1,1,1,1,0]), 3) == 0.592\n",
    "assert round(entropy([1,1,1,1,1,1,0,0]), 3) == 0.811\n",
    "assert round(entropy([2,2,1,1,0,0]), 3) == 1.585\n",
    "assert round(entropy([2,2,2,1,0]), 3) == 1.371\n",
    "assert round(entropy([2,2,2,0,0]), 3) == 0.971"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b)  Information Gain\n",
    "$$Gain(S,A) = Entropy(S) - \\sum_{v \\in Values(A)} \\frac{|S_v|}{|S|} Entropy(S_v)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def gain(S, A):\n",
    "    \"\"\"\n",
    "    Calculates the expected reduction in entropy due to sorting on A.\n",
    "    S: Target classes for observations in A.\n",
    "    A: Observations.\n",
    "    \"\"\"\n",
    "    sigma = 0\n",
    "    for v in set(A): # sets only contain unique values\n",
    "        S_v = [S[key] for (key, v_) in enumerate(A) if v_ == v]\n",
    "        sigma = sigma + ((len(S_v) / len(S)) * entropy(S_v))\n",
    "    return entropy(S) - sigma\n",
    "\n",
    "\n",
    "# See ML-03, Slide 12 & 13\n",
    "assert_S_ = [0,0,1,1,1,0,1,0,1,1,1,1,1,0]\n",
    "assert round(gain(assert_S_, [1,1,1,1,0,0,0,1,0,0,0,1,0,1]), 3) == .152\n",
    "assert round(gain(assert_S_, [0,1,0,0,0,1,1,0,0,0,1,1,0,1]), 3) == .048"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) ID3 [0p]\n",
    "Nothing to do here currently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from node import Node\n",
    "\n",
    "def id3(examples, attributes, target_attribute = None): \n",
    "    \"\"\"\n",
    "    Calculate a tree of Nodes (fields: label [string], children [list]) \n",
    "    using the ID3 algorithm found as pseudocode on Wikipedia. Including comments (currently).\n",
    "    \n",
    "    TODO: Needs a second pair of eyes and comments clean up. Comments kept for Wikipedia pseudocode reference.\n",
    "    \"\"\"\n",
    "    # Create a root node for the tree\n",
    "    # If all examples are positive, Return the single-node tree Root, with label = \n",
    "    # If all examples are negative, Return the single-node tree Root, with label = -.\n",
    "    if all(examples['targets'] == examples['targets'][0]):\n",
    "        return Node(examples['targets'][0], [])\n",
    "    \n",
    "    # If number of predicting attributes is empty, then Return the single node tree Root,\n",
    "    # with label = most common value of the target attribute in the examples.\n",
    "    if len(attributes) == 0:\n",
    "        return Node(Counter(data_sample[target_attribute] for data_sample in examples['data']).most_common(1), [])\n",
    "    \n",
    "    # A <-- The Attribute that best classifies examples.\n",
    "    gains = [gain(examples['targets'], [r[attribute] for r in examples['data']]) for attribute in attributes]\n",
    "    attribute = attributes[gains.index(min(gains))]\n",
    "\n",
    "    # Create a root node for the tree (2)\n",
    "    # Decision Tree attribute for Root = A.\n",
    "    root = Node(attribute, [])\n",
    "    \n",
    "    # Otherwise Begin\n",
    "    # For each possible value, vi, of A,\n",
    "    for vi in set(data_sample[attribute] for data_sample in examples['data']):\n",
    "        # Add a new tree branch below Root, corresponding to the test A = vi.\n",
    "        child = Node(vi, [])\n",
    "        root.children.append(child)\n",
    "        # Let Examples(vi) be the subset of examples that have the value vi for A\n",
    "        vi_indices = [idx for idx, data_sample in enumerate(examples['data']) if data_sample[attribute] == vi]\n",
    "        examples_vi = {\n",
    "            'data': [examples['data'][i] for i in vi_indices],\n",
    "            'targets': [examples['targets'][i] for i in vi_indices]\n",
    "        }\n",
    "\n",
    "        # If Examples(vi) is empty\n",
    "        if len(examples_vi['data']) == 0:\n",
    "            # Then below this new branch add a leaf node with label = most common target value in the examples\n",
    "            child.children.append(Counter(examples_vi['targets']).most_common(1))\n",
    "        else:\n",
    "            # Else below this new branch add the subtree ID3 (Examples(vi), Attributes – {A})\n",
    "            child.children.append(\n",
    "                id3(examples_vi, \\\n",
    "                    [attribute_ for attribute_ in attributes if not attribute_ == attribute], \\\n",
    "                    attribute)\n",
    "            )\n",
    "    # End\n",
    "\n",
    "    # Return root\n",
    "    return root"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c2) Apply ID3 algorithm.\n",
    "Again, nothing to do here currently for students."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Example dataset. See Wikipedia (add URL here).\n",
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "\n",
    "# Make sure our gain function handles the new dataset as expected.\n",
    "assert round(gain(iris.target, [r[2] for r in iris.data]), 3) == 1.446\n",
    "\n",
    "attributes = [idx for idx, _ in enumerate(iris.data[0])]\n",
    "tree = id3({'data': iris.data, 'targets': iris.target}, attributes)\n",
    "\n",
    "print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
